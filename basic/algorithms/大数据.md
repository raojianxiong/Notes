1. Map-Reduce Hadoop
   * Map阶段 -> 把大任务分成子任务
   * Reduce阶段 -> 把子任务并发处理，然后合并结果
   * 备份的考虑，分布式存储的设计细节，以及容灾策略
   * 任务分配策略与任务进度跟踪的细节设计，节点状态的呈现
   * 多用户权限的控制
2. 哈希函数
   * 散列函数，输入域非常大，单数输出域是固定范围，假设为S
   * 典型的哈希函数都拥有无限的输入值域
   * 输入值相同时，返回值一样
   * 输入值不同时，返回值可能一样，也可能不一样
   * 不同输入值得到的哈希值，整体均与的分布在输出域S上（以上是哈希函数的基础，这点是评价哈希函数优劣的关键）
3. 用map-reduce方法统计一篇文章中每个单词出现的个数
   * 文章预处理
   * 去掉文章中的标点符号，连接符处理，单词结尾判断，产生只包含单词的文本
   * map阶段 -> 对每个单词生成词频为1的记录
   * 但个单词的单一词频记录，通过哈希函数得到每个单词的哈希值，并根据该值分成若干组任务
   * reduce阶段 -> 单个子任务中同一种单词的词频进行合并
   * 所有记录统一合并
4. 请对10亿个IPV4的IP地址进行排序，每个IP只会出现一次
   * 布隆过滤器的使用
   * IPV4的IP数量大约为42亿个，将IP转换为无符号整数,10亿个IP大约占4G
   * 申请长度为$2^{32}$的bit类型数组，每个位置上是一个bit,只可表示0和1两种状态，大约占128兆
   * 标黑IP对应位置 ( 做法其实就是布隆过滤器的使用 ) ，即发现整数1，则标黑数组第一个
   * 最后通过从0位置遍历，把IP还原，这样排序是不是很简单了
5. 对10亿人的年龄进行排序
   * 计数排序，假设年龄最大值为200，定义长度为200的数组，将10亿个年龄放入取出
6. 有一个包含20亿个全是32位整数的大文件，在其中找到出现次数最多的数，但是内存限制只有2G
   * hansmap记录所有数出现的次数
   * key 4字节 整型 具体某一种数
   * value 4字节 整型 这种数出现的次数
   * 一条记录占有8字节，记录条数为2亿时，大约1.6G，显然内存不够用
   * 最优做法是通过哈希函数
   * 使用哈希函数进行分流，分成16个小文件(N) -> 同一种数不会被分流到不同文件中，对于不同的数，每个文件中含有的整数的种类几乎一样，这都是哈希函数的性质，本题可以用每个数对N求余
   * 全部处理完后，得到16个文件中各自的第一名
7. 32位无符号整数的范围是0 ~ 4294967295,现在有一个正好包含40亿个无符号整数的文件，所以在整个范围中必然有没有出现过的数。可以使用最多10兆的内存，只用找到一个没出现过的数即可，该如何找？
   * 如果用哈希表来记录所有的数，最差情况下将出现40亿个不同的数，每一条纪律占有4字节，大约需要16G内存
   * 如果利用布隆过滤器的方法，新建大小为$2^{32} -1$的数组bitmap，每个位置1bit,只能表示0或1两种状态，大约占用500m的空间
   * 但是如果0 ~ $2^{32}$ - 1范围分成64个空间，单个区间数为 $2^{32} /64 $ 个数，总共范围为42亿，但数一共有40亿，所以必然会有区间计数不足 $2^{32} / 64$，记为区间A
   * 再遍历一遍40亿个数，此时只对区间A上的数，并用新建的bitmap数组统计区间A上数出现的情况。500m / 64 ,不足10M
   * 总结：根据内存限制决定区间大小，根据区间大小，得到有多少个变量，来记录每个区间的数出现的次数，统计区间上的数出现的次数，找到不足的区间，利用bitmap对不满的区间，进行这个区间上的数进行词频统计
8. 某搜索公司一天的用户搜索词汇是海量的，假设有百亿的数据量，请设计一种求出每天最热100词的可行办法
   * 使用哈希函数进行分流，如果内存不足，那么就继续分流，最后处理每一个小文件，使用小根堆找出每个文件的TOP100，然后合并，最后再找出合并后的每个文件的TOP100，最后一直回溯到原始分流状态，完成。
9. 工程师常使用服务器集群来设计和实现数据缓存，以下是常见的策略。1.无论是添加、查询还是删除数据，都先将数据的ID通过哈希函数转换成一个哈希值，记为key 2.如果目前机器有N台，则计算key%N的值，这个值就是该数据所属机器编号，无论是添加、删除还是查询操作，都只在这台机器上进行，请分析这种缓存策略带来的问题，并提出改进的方案。
   * 潜在问题：如果增加或者删除机器，数据迁移的代价很大
   * 使用哈希函数进行分流，得到结果%N，当机器数N发生变化时，所有数据必须重新计算哈希值，以及对新的机器数M取余，来决定各自数据的归属
   * 这是利用一致性哈希算法，数据 ID 通过哈希值计算的结果映射到 0 ~ $2^{32}$ ,将这些数字首尾相连，想象成一个闭合的环形
   * 数据添加，数据ID映射到环的位置上，顺时针找到第一个机器，数据归属于它
   * 机器删除：数据ID在环上的位置，逆时针找到第一个机器，数据归属于它。
10. 哈希函数设计
    * 直接寻址法
      * $hash(key)=key 或者 hash(key) = a * key + b$
    * 取模法
      * $hash(key) = key mod p$
    * 数字分析法
    * 折叠法
    * 平方取中法
    * 保留余数法
      *  $hash(key) = key % p$
    * 随机数法
      * $hash(key) = random(key)$
11. 解决哈希冲突方法
    * 开发寻址法
      * 当发生地址冲突时，继续按照某种方法探测其它的存储地址，知道找到空闲的地址
    * 链表法
    * 再散列法
      * 当发生冲突时，使用第二个、第三个 .... 散列函数计算地址，知道无冲突为止，增加了时间消耗
    * 建立一个公共溢出区
12. 优缺点
    * hash 主要是用来进行快速存取，在O(1)时间复杂度里就可以查找到目标元素，或者判断其是否存在，hash数据结构里的数据对外是杂乱无序的，因此其具体存储位置及各个存储元素之间的相互关系是无法得知的，但是却可以在常熟时间里判断元素位置及存在与否。在处理海量数据的过程中，使用hash方法一般可以快速存取、统计某些数据，将大量数据进行分类，例如提取某日访问网站次数最多的IP地址。